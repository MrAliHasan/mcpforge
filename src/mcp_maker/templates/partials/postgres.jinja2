{% import "partials/macros.jinja2" as m %}
# ─── Database Connection Pool (Lazy Initialization) ───

DSN = DATABASE_URL
{% if ssl_enabled %}
# Enforce SSL/TLS for production security
if DSN and "sslmode" not in DSN:
    DSN = DSN + ("&" if "?" in DSN else "?") + "sslmode=require"
{% endif %}
_pg_pool = None


def _get_pool():
    """Lazily initialize the connection pool on first use."""
    global _pg_pool
    if _pg_pool is None:
        _pg_pool = psycopg2.pool.ThreadedConnectionPool(minconn=1, maxconn=10, dsn=DSN)
    return _pg_pool


def _get_connection():
    """Get a connection from the pool."""
    return _get_pool().getconn()


def _put_connection(conn):
    """Return a connection to the pool."""
    _get_pool().putconn(conn)

{% if consolidate %}
# ─── Consolidated Tools (Large Schema Mode) ───

{{ m.consolidated_whitelist(tables) }}

{{ m.consolidated_list_tables(ops) }}

{% if 'read' in ops %}
@mcp.tool()
def describe_table(table_name: str) -> dict:
    """Get the schema (columns and types) for a specific table."""
    table_name = _validate_table(table_name)
    conn = _get_connection()
    try:
        cursor = conn.cursor()
        cursor.execute("SELECT column_name, data_type FROM information_schema.columns WHERE table_schema='public' AND table_name=%s", (table_name,))
        return {row[0]: row[1] for row in cursor.fetchall()}
    except Exception as e:
        raise RuntimeError(f"describe_table failed: {e}") from e
    finally:
        _put_connection(conn)

@mcp.tool()
def query_database(table_name: str, filters: dict | None = None, limit: int = {{ default_limit }}, offset: int = 0) -> list[dict]:
    """Query a table with optional exact-match filters (e.g. {"status": "active"})."""
    table_name = _validate_table(table_name)
    conn = _get_connection()
    try:
        limit = min(limit, {{ max_limit }})
        query = f'SELECT * FROM "{table_name}"'
        params = []
        if filters:
            conditions = []
            for k, v in filters.items():
                conditions.append(f'"{k}" = %s')
                params.append(v)
            query += " WHERE " + " AND ".join(conditions)
        query += " LIMIT %s OFFSET %s"
        params.extend([limit, offset])
        cursor = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
        cursor.execute(query, params)
        return [dict(row) for row in cursor.fetchall()]
    except Exception as e:
        raise RuntimeError(f"query_database failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}

{% if 'insert' in ops %}
@mcp.tool()
def insert_record(table_name: str, data: dict) -> dict:
    """Insert a new record into a table."""
    table_name = _validate_table(table_name)
    conn = _get_connection()
    try:
        columns = [f'"{k}"' for k in data.keys()]
        placeholders = ["%s" for _ in data.keys()]
        values = list(data.values())
        query = f'INSERT INTO "{table_name}" ({", ".join(columns)}) VALUES ({", ".join(placeholders)}) RETURNING *'
        cursor = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
        cursor.execute(query, values)
        row = cursor.fetchone()
        conn.commit()
        return dict(row) if row else {}
    except Exception as e:
        conn.rollback()
        raise RuntimeError(f"insert_record failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}

{% if 'update' in ops %}
@mcp.tool()
def update_record(table_name: str, filters: dict, data: dict) -> list[dict]:
    """Update records in a table matching the exact filters."""
    table_name = _validate_table(table_name)
    conn = _get_connection()
    try:
        if not filters:
            raise ValueError("Filters are required for update to prevent mass modification")
        updates = [f'"{k}" = %s' for k in data.keys()]
        conditions = [f'"{k}" = %s' for k in filters.keys()]
        values = list(data.values()) + list(filters.values())
        query = f'UPDATE "{table_name}" SET {", ".join(updates)} WHERE {" AND ".join(conditions)} RETURNING *'
        cursor = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
        cursor.execute(query, values)
        rows = cursor.fetchall()
        conn.commit()
        return [dict(row) for row in rows]
    except Exception as e:
        conn.rollback()
        raise RuntimeError(f"update_record failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}

{% if 'delete' in ops %}
@mcp.tool()
def delete_record(table_name: str, filters: dict) -> dict:
    """Delete records from a table matching the exact filters."""
    table_name = _validate_table(table_name)
    conn = _get_connection()
    try:
        if not filters:
            raise ValueError("Filters are required for deletion to prevent mass deletion")
        conditions = [f'"{k}" = %s' for k in filters.keys()]
        values = list(filters.values())
        query = f'DELETE FROM "{table_name}" WHERE {" AND ".join(conditions)}'
        cursor = conn.cursor()
        cursor.execute(query, values)
        count = cursor.rowcount
        conn.commit()
        return {"deleted": count}
    except Exception as e:
        conn.rollback()
        raise RuntimeError(f"delete_record failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}

{% else %}

{% for table in tables %}

{{ m.table_header(table) }}



{% if 'read' in ops %}
@mcp.tool()
def list_{{ table.name }}(limit: int = {{ default_limit }}, offset: int = 0, sort_field: str | None = None, sort_direction: str = "asc", fields: str | None = None{% for col in table.columns if col.type.value in ('date', 'datetime') %}, {{ col.name }}_from: str | None = None, {{ col.name }}_to: str | None = None{% endfor %}) -> dict:
    """List rows from the '{{ table.name }}' table.

    Args:
        limit: Maximum number of rows to return (default: {{ default_limit }}, max: {{ max_limit }}).
        offset: Number of rows to skip for pagination.
        sort_field: Column name to sort by.
        sort_direction: 'asc' or 'desc'.
        fields: Comma-separated column names to return (default: all).
        {% for col in table.columns if col.type.value in ('date', 'datetime') %}
        {{ col.name }}_from: Filter {{ col.name }} >= this value (ISO format).
        {{ col.name }}_to: Filter {{ col.name }} <= this value (ISO format).
        {% endfor %}

    Returns:
        Dict with 'results', 'total', 'has_more', 'next_offset'.
    """
    conn = _get_connection()
    try:
        limit = min(limit, {{ max_limit }})
        cursor = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
        _valid_cols = { {% for col in table.columns %}"{{ col.name }}", {% endfor %} }

        if fields:
            selected = [f.strip() for f in fields.split(",") if f.strip() in _valid_cols]
            select_clause = ", ".join(f'"{c}"' for c in selected) if selected else "*"
        else:
            select_clause = "*"

        query = f'SELECT {select_clause} FROM "{{ table.name }}"'
        params = []
        conditions = []
        {% for col in table.columns if col.type.value in ('date', 'datetime') %}
        if {{ col.name }}_from:
            conditions.append('"{{ col.name }}" >= %s')
            params.append({{ col.name }}_from)
        if {{ col.name }}_to:
            conditions.append('"{{ col.name }}" <= %s')
            params.append({{ col.name }}_to)
        {% endfor %}
        if conditions:
            query += " WHERE " + " AND ".join(conditions)

        count_query = f'SELECT COUNT(*) FROM "{{ table.name }}"'
        if conditions:
            count_query += " WHERE " + " AND ".join(conditions)
        cursor.execute(count_query, params[:])
        total = cursor.fetchone()["count"]

        if sort_field and sort_field in _valid_cols:
            direction = "DESC" if sort_direction.lower() == "desc" else "ASC"
            query += f' ORDER BY "{sort_field}" {direction}'
        query += ' LIMIT %s OFFSET %s'
        params.extend([limit, offset])
        cursor.execute(query, params)
        rows = [dict(row) for row in cursor.fetchall()]
        cursor.close()
        return {
            "results": rows,
            "total": total,
            "has_more": (offset + limit) < total,
            "next_offset": offset + limit if (offset + limit) < total else None,
        }
    except Exception as e:
        raise RuntimeError(f"list_{{ table.name }} failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}


{% if table.primary_key_columns %}
{% set pk = table.primary_key_columns[0] %}

{% if 'read' in ops %}
@mcp.tool()
def get_{{ table.name }}_by_{{ pk.name }}({{ pk.name }}: {{ 'int' if pk.type.value == 'integer' else 'str' }}) -> dict | None:
    """Get a single row from '{{ table.name }}' by its {{ pk.name }}."""
    conn = _get_connection()
    try:
        cursor = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
        cursor.execute(
            'SELECT * FROM "{{ table.name }}" WHERE "{{ pk.name }}" = %s',
            ({{ pk.name }},),
        )
        row = cursor.fetchone()
        cursor.close()
        return dict(row) if row else None
    except Exception as e:
        raise RuntimeError(f"get_{{ table.name }}_by_{{ pk.name }} failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}

{% endif %}

{% if table.searchable_columns %}

{% if 'read' in ops %}
@mcp.tool()
def search_{{ table.name }}(query: str, limit: int = {{ default_limit }}) -> list[dict]:
    """Search the '{{ table.name }}' table by matching against text columns.

    This uses ILIKE pattern matching. For large tables with millions of rows,
    consider using the semantic_search tool instead for better performance.
    """
    conn = _get_connection()
    try:
        limit = min(limit, {{ max_limit }})
        cursor = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
        conditions = []
        params = []
        {% for col in table.searchable_columns %}
        {% if col.type.value == 'string' %}
        conditions.append('"{{ col.name }}" ILIKE %s')
        params.append(f"%{query}%")
        {% endif %}
        {% endfor %}

        if not conditions:
            cursor.close()
            return []

        where_clause = " OR ".join(conditions)
        params.append(limit)
        cursor.execute(
            f'SELECT * FROM "{{ table.name }}" WHERE {where_clause} LIMIT %s',
            params,
        )
        rows = [dict(row) for row in cursor.fetchall()]
        cursor.close()
        return rows
    except Exception as e:
        raise RuntimeError(f"search_{{ table.name }} failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}

{% endif %}


{% if 'read' in ops %}
@mcp.tool()
def count_{{ table.name }}() -> int:
    """Get the total number of rows in the '{{ table.name }}' table."""
    conn = _get_connection()
    try:
        cursor = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
        cursor.execute('SELECT COUNT(*) as cnt FROM "{{ table.name }}"')
        count = cursor.fetchone()["cnt"]
        cursor.close()
        return count
    except Exception as e:
        raise RuntimeError(f"count_{{ table.name }} failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}



{{ m.schema_tool(table, ops) }}

{% if 'read' in ops %}
@mcp.tool()
def aggregate_{{ table.name }}(group_by: str, agg_function: str = "count", agg_column: str = "*", limit: int = 20) -> list[dict]:
    """Aggregate data in '{{ table.name }}' using GROUP BY.

    Args:
        group_by: Column to group by (e.g. '{{ table.columns[0].name }}').
        agg_function: 'count', 'sum', 'avg', 'min', or 'max'.
        agg_column: Column to aggregate (default: '*' for count).
        limit: Maximum groups to return.
    """
    _valid_cols = { {% for col in table.columns %}"{{ col.name }}", {% endfor %} }
    if group_by not in _valid_cols:
        raise ValueError(f"Invalid group_by: {group_by}. Available: {', '.join(sorted(_valid_cols))}")
    agg_function = agg_function.upper()
    if agg_function not in ("COUNT", "SUM", "AVG", "MIN", "MAX"):
        raise ValueError(f"Invalid agg_function: {agg_function}. Use: count, sum, avg, min, max")
    if agg_column != "*" and agg_column not in _valid_cols:
        raise ValueError(f"Invalid agg_column: {agg_column}")
    conn = _get_connection()
    try:
        agg_col = "*" if agg_column == "*" else f'"{agg_column}"'
        cursor = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
        cursor.execute(
            f'SELECT "{group_by}" as "group", {agg_function}({agg_col}) as "value" '
            f'FROM "{{ table.name }}" GROUP BY "{group_by}" ORDER BY "value" DESC LIMIT %s',
            (min(limit, 100),),
        )
        rows = [dict(row) for row in cursor.fetchall()]
        cursor.close()
        return rows
    except Exception as e:
        raise RuntimeError(f"aggregate_{{ table.name }} failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}

{% if ('insert' in ops or 'update' in ops or 'delete' in ops) and table.primary_key_columns %}
{% set pk = table.primary_key_columns[0] %}


{% if 'insert' in ops %}
@mcp.tool()
def insert_{{ table.name }}({% for col in table.columns if not col.primary_key %}{{ col.name }}: {{ 'int' if col.type.value == 'integer' else ('float' if col.type.value == 'float' else ('bool' if col.type.value == 'boolean' else 'str')) }}{{ ' | None = None' if col.nullable else '' }}{{ ', ' if not loop.last else '' }}{% endfor %}) -> dict:
    """Insert a new row into the '{{ table.name }}' table."""
    conn = _get_connection()
    try:
        cursor = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
        columns = []
        values = []
        {% for col in table.columns if not col.primary_key %}
        if {{ col.name }} is not None:
            columns.append('"{{ col.name }}"')
            values.append({{ col.name }})
        {% endfor %}

        placeholders = ", ".join(["%s" for _ in values])
        col_names = ", ".join(columns)
        cursor.execute(
            f'INSERT INTO "{{ table.name }}" ({col_names}) VALUES ({placeholders}) RETURNING *',
            values,
        )
        row = cursor.fetchone()
        conn.commit()
        cursor.close()
        return dict(row) if row else {}
    except Exception as e:
        conn.rollback()
        raise RuntimeError(f"insert_{{ table.name }} failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}



{% if 'update' in ops %}
@mcp.tool()
def update_{{ table.name }}_by_{{ pk.name }}({{ pk.name }}: {{ 'int' if pk.type.value == 'integer' else 'str' }}, {% for col in table.columns if not col.primary_key %}{{ col.name }}: {{ 'int' if col.type.value == 'integer' else ('float' if col.type.value == 'float' else ('bool' if col.type.value == 'boolean' else 'str')) }} | None = None{{ ', ' if not loop.last else '' }}{% endfor %}) -> dict | None:
    """Update an existing row in the '{{ table.name }}' table."""
    conn = _get_connection()
    try:
        cursor = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
        updates = []
        values = []
        {% for col in table.columns if not col.primary_key %}
        if {{ col.name }} is not None:
            updates.append('"{{ col.name }}" = %s')
            values.append({{ col.name }})
        {% endfor %}

        if not updates:
            cursor.close()
            return get_{{ table.name }}_by_{{ pk.name }}({{ pk.name }})

        set_clause = ", ".join(updates)
        values.append({{ pk.name }})
        cursor.execute(
            f'UPDATE "{{ table.name }}" SET {set_clause} WHERE "{{ pk.name }}" = %s RETURNING *',
            values,
        )
        row = cursor.fetchone()
        conn.commit()
        cursor.close()
        return dict(row) if row else None
    except Exception as e:
        conn.rollback()
        raise RuntimeError(f"update_{{ table.name }}_by_{{ pk.name }} failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}



{% if 'delete' in ops %}
@mcp.tool()
def delete_{{ table.name }}_by_{{ pk.name }}({{ pk.name }}: {{ 'int' if pk.type.value == 'integer' else 'str' }}) -> dict:
    """Delete a row from the '{{ table.name }}' table."""
    conn = _get_connection()
    try:
        cursor = conn.cursor()
        cursor.execute(
            'DELETE FROM "{{ table.name }}" WHERE "{{ pk.name }}" = %s',
            ({{ pk.name }},),
        )
        deleted = cursor.rowcount
        conn.commit()
        cursor.close()
        return {"deleted": deleted, "{{ pk.name }}": {{ pk.name }}}
    except Exception as e:
        conn.rollback()
        raise RuntimeError(f"delete_{{ table.name }}_by_{{ pk.name }} failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}

{% if 'insert' in ops %}
@mcp.tool()
def batch_insert_{{ table.name }}(records: list[dict]) -> dict:
    """Insert multiple rows into '{{ table.name }}' in a single transaction.

    Args:
        records: List of dictionaries, each representing a row.
    """
    conn = _get_connection()
    try:
        cursor = conn.cursor()
        inserted = 0
        for record in records:
            cols = [c for c in record.keys() if c != "{{ pk.name }}"]
            vals = [record[c] for c in cols]
            placeholders = ", ".join(["%s"] * len(cols))
            col_names = ", ".join(f'"{c}"' for c in cols)
            cursor.execute(
                f'INSERT INTO "{{ table.name }}" ({col_names}) VALUES ({placeholders})',
                vals,
            )
            inserted += 1
        conn.commit()
        cursor.close()
        return {"inserted": inserted}
    except Exception as e:
        conn.rollback()
        raise RuntimeError(f"batch_insert_{{ table.name }} failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}

{% if 'delete' in ops %}
@mcp.tool()
def batch_delete_{{ table.name }}(ids: list) -> dict:
    """Delete multiple rows from '{{ table.name }}' by their {{ pk.name }} values.

    Args:
        ids: List of {{ pk.name }} values to delete.
    """
    conn = _get_connection()
    try:
        cursor = conn.cursor()
        placeholders = ", ".join(["%s"] * len(ids))
        cursor.execute(
            f'DELETE FROM "{{ table.name }}" WHERE "{{ pk.name }}" IN ({placeholders})',
            ids,
        )
        conn.commit()
        deleted = cursor.rowcount
        cursor.close()
        return {"deleted": deleted}
    except Exception as e:
        conn.rollback()
        raise RuntimeError(f"batch_delete_{{ table.name }} failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}

{% endif %}
{% endfor %}

{% endif %}

{% if foreign_keys and 'read' in ops %}
# ═══════════════════════════════════════════════════════
# Relationship Joins (auto-detected from foreign keys)
# ═══════════════════════════════════════════════════════

{% for fk in foreign_keys %}
@mcp.tool()
def join_{{ fk.from_table }}_with_{{ fk.to_table }}(limit: int = {{ default_limit }}, offset: int = 0) -> list[dict]:
    """Join '{{ fk.from_table }}' with '{{ fk.to_table }}' via {{ fk.from_table }}.{{ fk.from_column }} → {{ fk.to_table }}.{{ fk.to_column }}.

    Args:
        limit: Maximum rows to return (default: {{ default_limit }}, max: {{ max_limit }}).
        offset: Number of rows to skip for pagination.
    """
    conn = _get_connection()
    try:
        limit = min(limit, {{ max_limit }})
        cursor = conn.cursor(cursor_factory=psycopg2.extras.RealDictCursor)
        cursor.execute(
            'SELECT "{{ fk.from_table }}".*, "{{ fk.to_table }}".* '
            'FROM "{{ fk.from_table }}" '
            'JOIN "{{ fk.to_table }}" ON "{{ fk.from_table }}"."{{ fk.from_column }}" = "{{ fk.to_table }}"."{{ fk.to_column }}" '
            'LIMIT %s OFFSET %s',
            (limit, offset),
        )
        rows = [dict(row) for row in cursor.fetchall()]
        cursor.close()
        return rows
    except Exception as e:
        raise RuntimeError(f"join_{{ fk.from_table }}_with_{{ fk.to_table }} failed: {e}") from e
    finally:
        _put_connection(conn)

{% endfor %}
{% endif %}
