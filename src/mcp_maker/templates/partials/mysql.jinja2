{% import "partials/macros.jinja2" as m %}
# ─── Database Connection Pool ───

import queue as _queue
import urllib.parse as _urlparse

_parsed = _urlparse.urlparse(DATABASE_URL)

MYSQL_CONFIG = {
    "host": _parsed.hostname or "localhost",
    "port": _parsed.port or 3306,
    "user": _parsed.username or "root",
    "password": _parsed.password or "",
    "database": _parsed.path.lstrip('/') or "",
{% if ssl_enabled %}
    "ssl": {"ssl": True},
{% endif %}
}

_mysql_pool = _queue.Queue(maxsize=10)


def _get_connection():
    """Get a MySQL connection from the pool, or create a new one."""
    try:
        conn = _mysql_pool.get_nowait()
        conn.ping(reconnect=True)
        return conn
    except _queue.Empty:
        return pymysql.connect(
            **MYSQL_CONFIG,
            cursorclass=pymysql.cursors.DictCursor,
        )


def _put_connection(conn):
    """Return a MySQL connection to the pool."""
    try:
        _mysql_pool.put_nowait(conn)
    except _queue.Full:
        conn.close()

{% if consolidate %}
# ─── Consolidated Tools (Large Schema Mode) ───

{{ m.consolidated_whitelist(tables) }}

{{ m.consolidated_list_tables(ops) }}

{% if 'read' in ops %}
@mcp.tool()
def describe_table(table_name: str) -> dict:
    """Get the schema (columns and types) for a specific table."""
    table_name = _validate_table(table_name)
    conn = _get_connection()
    try:
        cursor = conn.cursor()
        cursor.execute("SELECT column_name, data_type FROM information_schema.columns WHERE table_schema=DATABASE() AND table_name=%s", (table_name,))
        schema = {row["column_name"]: row["data_type"] for row in cursor.fetchall()}
        cursor.close()
        return schema
    except Exception as e:
        raise RuntimeError(f"describe_table failed: {e}") from e
    finally:
        _put_connection(conn)

@mcp.tool()
def query_database(table_name: str, filters: dict | None = None, limit: int = {{ default_limit }}, offset: int = 0) -> list[dict]:
    """Query a table with optional exact-match filters."""
    table_name = _validate_table(table_name)
    conn = _get_connection()
    try:
        limit = min(limit, {{ max_limit }})
        query = f'SELECT * FROM `{table_name}`'
        params = []
        if filters:
            conditions = []
            for k, v in filters.items():
                conditions.append(f'`{k}` = %s')
                params.append(v)
            query += " WHERE " + " AND ".join(conditions)
        query += " LIMIT %s OFFSET %s"
        params.extend([limit, offset])
        cursor = conn.cursor()
        cursor.execute(query, params)
        rows = [dict(row) for row in cursor.fetchall()]
        cursor.close()
        return rows
    except Exception as e:
        raise RuntimeError(f"query_database failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}

{% if 'insert' in ops %}
@mcp.tool()
def insert_record(table_name: str, data: dict) -> dict:
    """Insert a new record into a table."""
    table_name = _validate_table(table_name)
    conn = _get_connection()
    try:
        columns = [f'`{k}`' for k in data.keys()]
        placeholders = ["%s" for _ in data.keys()]
        values = list(data.values())
        query = f'INSERT INTO `{table_name}` ({", ".join(columns)}) VALUES ({", ".join(placeholders)})'
        cursor = conn.cursor()
        cursor.execute(query, values)
        new_id = cursor.lastrowid
        conn.commit()
        cursor.close()
        return {"inserted": True, "lastrowid": new_id}
    except Exception as e:
        conn.rollback()
        raise RuntimeError(f"insert_record failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}

{% if 'update' in ops %}
@mcp.tool()
def update_record(table_name: str, filters: dict, data: dict) -> dict:
    """Update records in a table matching the exact filters."""
    table_name = _validate_table(table_name)
    conn = _get_connection()
    try:
        if not filters:
            raise ValueError("Filters are required for update to prevent mass modification")
        updates = [f'`{k}` = %s' for k in data.keys()]
        conditions = [f'`{k}` = %s' for k in filters.keys()]
        values = list(data.values()) + list(filters.values())
        query = f'UPDATE `{table_name}` SET {", ".join(updates)} WHERE {" AND ".join(conditions)}'
        cursor = conn.cursor()
        cursor.execute(query, values)
        count = cursor.rowcount
        conn.commit()
        cursor.close()
        return {"updated": count}
    except Exception as e:
        conn.rollback()
        raise RuntimeError(f"update_record failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}

{% if 'delete' in ops %}
@mcp.tool()
def delete_record(table_name: str, filters: dict) -> dict:
    """Delete records from a table matching the exact filters."""
    table_name = _validate_table(table_name)
    conn = _get_connection()
    try:
        if not filters:
            raise ValueError("Filters are required for deletion to prevent mass deletion")
        conditions = [f'`{k}` = %s' for k in filters.keys()]
        values = list(filters.values())
        query = f'DELETE FROM `{table_name}` WHERE {" AND ".join(conditions)}'
        cursor = conn.cursor()
        cursor.execute(query, values)
        count = cursor.rowcount
        conn.commit()
        cursor.close()
        return {"deleted": count}
    except Exception as e:
        conn.rollback()
        raise RuntimeError(f"delete_record failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}

{% else %}

{% for table in tables %}

{{ m.table_header(table) }}



{% if 'read' in ops %}
@mcp.tool()
def list_{{ table.name }}(limit: int = {{ default_limit }}, offset: int = 0, sort_field: str | None = None, sort_direction: str = "asc", fields: str | None = None{% for col in table.columns if col.type.value in ('date', 'datetime') %}, {{ col.name }}_from: str | None = None, {{ col.name }}_to: str | None = None{% endfor %}) -> dict:
    """List rows from the '{{ table.name }}' table.

    Args:
        limit: max rows (default: {{ default_limit }}, max: {{ max_limit }}).
        offset: rows to skip.
        sort_field: column to sort by.
        sort_direction: 'asc' or 'desc'.
        fields: comma-separated column names (default: all).
        {% for col in table.columns if col.type.value in ('date', 'datetime') %}
        {{ col.name }}_from: Filter {{ col.name }} >= value.
        {{ col.name }}_to: Filter {{ col.name }} <= value.
        {% endfor %}

    Returns:
        Dict with 'results', 'total', 'has_more', 'next_offset'.
    """
    conn = _get_connection()
    try:
        limit = min(limit, {{ max_limit }})
        cursor = conn.cursor()
        _valid_cols = { {% for col in table.columns %}"{{ col.name }}", {% endfor %} }

        if fields:
            selected = [f.strip() for f in fields.split(",") if f.strip() in _valid_cols]
            select_clause = ", ".join(f'`{c}`' for c in selected) if selected else "*"
        else:
            select_clause = "*"

        query = f"SELECT {select_clause} FROM `{{ table.name }}`"
        params = []
        conditions = []
        {% for col in table.columns if col.type.value in ('date', 'datetime') %}
        if {{ col.name }}_from:
            conditions.append('`{{ col.name }}` >= %s')
            params.append({{ col.name }}_from)
        if {{ col.name }}_to:
            conditions.append('`{{ col.name }}` <= %s')
            params.append({{ col.name }}_to)
        {% endfor %}
        if conditions:
            query += " WHERE " + " AND ".join(conditions)

        count_query = f"SELECT COUNT(*) as cnt FROM `{{ table.name }}`"
        if conditions:
            count_query += " WHERE " + " AND ".join(conditions)
        cursor.execute(count_query, params[:])
        total = cursor.fetchone()["cnt"]

        if sort_field and sort_field in _valid_cols:
            direction = "DESC" if sort_direction.lower() == "desc" else "ASC"
            query += f" ORDER BY `{sort_field}` {direction}"
        query += " LIMIT %s OFFSET %s"
        params.extend([limit, offset])
        cursor.execute(query, params)
        rows = [dict(row) for row in cursor.fetchall()]
        cursor.close()
        return {
            "results": rows,
            "total": total,
            "has_more": (offset + limit) < total,
            "next_offset": offset + limit if (offset + limit) < total else None,
        }
    except Exception as e:
        raise RuntimeError(f"list_{{ table.name }} failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}


{% if table.primary_key_columns %}
{% set pk = table.primary_key_columns[0] %}

{% if 'read' in ops %}
@mcp.tool()
def get_{{ table.name }}_by_{{ pk.name }}({{ pk.name }}: {{ 'int' if pk.type.value == 'integer' else 'str' }}) -> dict | None:
    """Get a single row from '{{ table.name }}' by its {{ pk.name }}."""
    conn = _get_connection()
    try:
        cursor = conn.cursor()
        cursor.execute(
            "SELECT * FROM `{{ table.name }}` WHERE `{{ pk.name }}` = %s",
            ({{ pk.name }},),
        )
        row = cursor.fetchone()
        cursor.close()
        return dict(row) if row else None
    except Exception as e:
        raise RuntimeError(f"get_{{ table.name }}_by_{{ pk.name }} failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}

{% endif %}

{% if table.searchable_columns %}

{% if 'read' in ops %}
@mcp.tool()
def search_{{ table.name }}(query: str, limit: int = {{ default_limit }}) -> list[dict]:
    """Search the '{{ table.name }}' table by matching against text columns.

    This uses LIKE pattern matching. For large tables with millions of rows,
    consider using the semantic_search tool instead for better performance.
    """
    conn = _get_connection()
    try:
        limit = min(limit, {{ max_limit }})
        cursor = conn.cursor()
        conditions = []
        params = []
        {% for col in table.searchable_columns %}
        {% if col.type.value == 'string' %}
        conditions.append("`{{ col.name }}` LIKE %s")
        params.append(f"%{query}%")
        {% endif %}
        {% endfor %}

        if not conditions:
            cursor.close()
            return []

        where_clause = " OR ".join(conditions)
        params.append(limit)
        cursor.execute(
            f"SELECT * FROM `{{ table.name }}` WHERE {where_clause} LIMIT %s",
            params,
        )
        rows = [dict(row) for row in cursor.fetchall()]
        cursor.close()
        return rows
    except Exception as e:
        raise RuntimeError(f"search_{{ table.name }} failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}

{% endif %}


{% if 'read' in ops %}
@mcp.tool()
def count_{{ table.name }}() -> int:
    """Get the total number of rows in the '{{ table.name }}' table."""
    conn = _get_connection()
    try:
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) as cnt FROM `{{ table.name }}`")
        count = cursor.fetchone()["cnt"]
        cursor.close()
        return count
    except Exception as e:
        raise RuntimeError(f"count_{{ table.name }} failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}



{{ m.schema_tool(table, ops) }}

{% if 'read' in ops %}
@mcp.tool()
def aggregate_{{ table.name }}(group_by: str, agg_function: str = "count", agg_column: str = "*", limit: int = 20) -> list[dict]:
    """Aggregate data in '{{ table.name }}' using GROUP BY.

    Args:
        group_by: Column to group by (e.g. '{{ table.columns[0].name }}').
        agg_function: 'count', 'sum', 'avg', 'min', or 'max'.
        agg_column: Column to aggregate (default: '*' for count).
        limit: Maximum groups to return.
    """
    _valid_cols = { {% for col in table.columns %}"{{ col.name }}", {% endfor %} }
    if group_by not in _valid_cols:
        raise ValueError(f"Invalid group_by: {group_by}. Available: {', '.join(sorted(_valid_cols))}")
    agg_function = agg_function.upper()
    if agg_function not in ("COUNT", "SUM", "AVG", "MIN", "MAX"):
        raise ValueError(f"Invalid agg_function: {agg_function}. Use: count, sum, avg, min, max")
    if agg_column != "*" and agg_column not in _valid_cols:
        raise ValueError(f"Invalid agg_column: {agg_column}")
    conn = _get_connection()
    try:
        agg_col = "*" if agg_column == "*" else f'`{agg_column}`'
        cursor = conn.cursor()
        cursor.execute(
            f"SELECT `{group_by}` as `group`, {agg_function}({agg_col}) as `value` "
            f"FROM `{{ table.name }}` GROUP BY `{group_by}` ORDER BY `value` DESC LIMIT %s",
            (min(limit, 100),),
        )
        rows = [dict(row) for row in cursor.fetchall()]
        cursor.close()
        return rows
    except Exception as e:
        raise RuntimeError(f"aggregate_{{ table.name }} failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}

{% if ('insert' in ops or 'update' in ops or 'delete' in ops) and table.primary_key_columns %}
{% set pk = table.primary_key_columns[0] %}


{% if 'insert' in ops %}
@mcp.tool()
def insert_{{ table.name }}({% for col in table.columns if not col.primary_key %}{{ col.name }}: {{ 'int' if col.type.value == 'integer' else ('float' if col.type.value == 'float' else ('bool' if col.type.value == 'boolean' else 'str')) }}{{ ' | None = None' if col.nullable else '' }}{{ ', ' if not loop.last else '' }}{% endfor %}) -> dict:
    """Insert a new row into the '{{ table.name }}' table."""
    conn = _get_connection()
    try:
        cursor = conn.cursor()
        columns = []
        values = []
        {% for col in table.columns if not col.primary_key %}
        if {{ col.name }} is not None:
            columns.append("`{{ col.name }}`")
            values.append({{ col.name }})
        {% endfor %}

        placeholders = ", ".join(["%s" for _ in values])
        col_names = ", ".join(columns)
        cursor.execute(
            f"INSERT INTO `{{ table.name }}` ({col_names}) VALUES ({placeholders})",
            values,
        )
        conn.commit()
        new_id = cursor.lastrowid
        cursor.close()
        return get_{{ table.name }}_by_{{ pk.name }}(new_id)
    except Exception as e:
        conn.rollback()
        raise RuntimeError(f"insert_{{ table.name }} failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}



{% if 'delete' in ops %}
@mcp.tool()
def delete_{{ table.name }}_by_{{ pk.name }}({{ pk.name }}: {{ 'int' if pk.type.value == 'integer' else 'str' }}) -> dict:
    """Delete a row from the '{{ table.name }}' table."""
    conn = _get_connection()
    try:
        cursor = conn.cursor()
        cursor.execute(
            "DELETE FROM `{{ table.name }}` WHERE `{{ pk.name }}` = %s",
            ({{ pk.name }},),
        )
        deleted = cursor.rowcount
        conn.commit()
        cursor.close()
        return {"deleted": deleted, "{{ pk.name }}": {{ pk.name }}}
    except Exception as e:
        conn.rollback()
        raise RuntimeError(f"delete_{{ table.name }}_by_{{ pk.name }} failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}

{% if 'insert' in ops %}
@mcp.tool()
def batch_insert_{{ table.name }}(records: list[dict]) -> dict:
    """Insert multiple rows into '{{ table.name }}' in a single transaction.

    Args:
        records: List of dictionaries, each representing a row.
    """
    conn = _get_connection()
    try:
        cursor = conn.cursor()
        inserted = 0
        for record in records:
            cols = [c for c in record.keys() if c != "{{ pk.name }}"]
            vals = [record[c] for c in cols]
            placeholders = ", ".join(["%s"] * len(cols))
            col_names = ", ".join(f'`{c}`' for c in cols)
            cursor.execute(
                f"INSERT INTO `{{ table.name }}` ({col_names}) VALUES ({placeholders})",
                vals,
            )
            inserted += 1
        conn.commit()
        cursor.close()
        return {"inserted": inserted}
    except Exception as e:
        conn.rollback()
        raise RuntimeError(f"batch_insert_{{ table.name }} failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}

{% if 'delete' in ops %}
@mcp.tool()
def batch_delete_{{ table.name }}(ids: list) -> dict:
    """Delete multiple rows from '{{ table.name }}' by their {{ pk.name }} values.

    Args:
        ids: List of {{ pk.name }} values to delete.
    """
    conn = _get_connection()
    try:
        cursor = conn.cursor()
        placeholders = ", ".join(["%s"] * len(ids))
        cursor.execute(
            f"DELETE FROM `{{ table.name }}` WHERE `{{ pk.name }}` IN ({placeholders})",
            ids,
        )
        conn.commit()
        deleted = cursor.rowcount
        cursor.close()
        return {"deleted": deleted}
    except Exception as e:
        conn.rollback()
        raise RuntimeError(f"batch_delete_{{ table.name }} failed: {e}") from e
    finally:
        _put_connection(conn)
{% endif %}

{% endif %}
{% endfor %}

{% endif %}

{% if foreign_keys and 'read' in ops %}
# ═══════════════════════════════════════════════════════
# Relationship Joins (auto-detected from foreign keys)
# ═══════════════════════════════════════════════════════

{% for fk in foreign_keys %}
@mcp.tool()
def join_{{ fk.from_table }}_with_{{ fk.to_table }}(limit: int = {{ default_limit }}, offset: int = 0) -> list[dict]:
    """Join '{{ fk.from_table }}' with '{{ fk.to_table }}' via {{ fk.from_table }}.{{ fk.from_column }} → {{ fk.to_table }}.{{ fk.to_column }}.

    Args:
        limit: Maximum rows to return (default: {{ default_limit }}, max: {{ max_limit }}).
        offset: Number of rows to skip for pagination.
    """
    conn = _get_connection()
    try:
        limit = min(limit, {{ max_limit }})
        cursor = conn.cursor()
        cursor.execute(
            "SELECT `{{ fk.from_table }}`.*, `{{ fk.to_table }}`.* "
            "FROM `{{ fk.from_table }}` "
            "JOIN `{{ fk.to_table }}` ON `{{ fk.from_table }}`.`{{ fk.from_column }}` = `{{ fk.to_table }}`.`{{ fk.to_column }}` "
            "LIMIT %s OFFSET %s",
            (limit, offset),
        )
        rows = [dict(row) for row in cursor.fetchall()]
        cursor.close()
        return rows
    except Exception as e:
        raise RuntimeError(f"join_{{ fk.from_table }}_with_{{ fk.to_table }} failed: {e}") from e
    finally:
        _put_connection(conn)

{% endfor %}
{% endif %}
